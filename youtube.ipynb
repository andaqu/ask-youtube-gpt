{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from nltk.tokenize import TextTilingTokenizer  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"https://www.youtube.com/watch?v=VcVfceTsD0A&t=163s\"\n",
    "video_id = url.split(\"=\")[1]\n",
    "\n",
    "raw = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "\n",
    "response = requests.get(f\"https://noembed.com/embed?dataType=json&url={url}\")\n",
    "data = json.loads(response.content)\n",
    "\n",
    "title, author = data[\"title\"], data[\"author_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of dictionaries to a pandas dataframe\n",
    "df = pd.DataFrame(raw)\n",
    "\n",
    "# Add end column\n",
    "df['end'] = df['start'] + df['duration']\n",
    "\n",
    "# Add a new column to the dataframe called 'total_words' that contains the total number of words so far in the transcript\n",
    "df['total_words'] = df['text'].apply(lambda x: len(x.split())).cumsum()\n",
    "\n",
    "# Add \"\\n\\n\" at the end of df[\"text\"]\n",
    "df[\"text\"] = df[\"text\"] + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the text column into a single string and save to a transcript variable\n",
    "\n",
    "transcript = df['text'].str.cat(sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = TextTilingTokenizer()\n",
    "\n",
    "# Tokenize the transcript into segments using the TextTilingTokenizer\n",
    "segments = tt.tokenize(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove \\n\\n from each segment\n",
    "segments = [segment.replace('\\n\\n','').strip() for segment in segments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate a list of word count for each segment\n",
    "segments_wc = [len(segment.split()) for segment in segments]\n",
    "\n",
    "# Make it cumulative\n",
    "segments_wc = np.cumsum(segments_wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_timestamp(seconds):\n",
    "\n",
    "    seconds = int(seconds)\n",
    "\n",
    "    minutes = seconds // 60\n",
    "    seconds_remaining = f\"{seconds % 60}\"\n",
    "    \n",
    "    if len(seconds_remaining) == 1:\n",
    "        seconds_remaining = \"0\" + seconds_remaining\n",
    "\n",
    "    return f\"{minutes}:{seconds_remaining}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each value in segments_wc, get the index of the closest value in df['total_words']\n",
    "# This will be the index of the row in df that is closest to the end of each segment\n",
    "idx = [np.argmin(np.abs(df['total_words'] - total_words)) for total_words in segments_wc]\n",
    "\n",
    "# Get segment end times from idx\n",
    "segment_end_times = df['end'].iloc[idx].values\n",
    "\n",
    "# Add 0.0 to the beginning of segment_end_times\n",
    "segment_end_times = np.insert(segment_end_times, 0, 0.0)\n",
    "\n",
    "# segment_times is a list of tuples containing the start and end times of each segment\n",
    "segment_times = [(to_timestamp(segment_end_times[i-1]), to_timestamp(segment_end_times[i])) for i in range(1,len(segment_end_times))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At the beginning of each segment, add the title, author, and segment times\n",
    "segment_text = [f\"'{title}' by {author}\\nTimestamp: {segment_time}\\n\\n{segment}\" for segment, segment_time in zip(segments, segment_times)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
